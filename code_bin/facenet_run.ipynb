{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fr_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_blocks_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 50\n",
    "#ready_to_detect_identity = True\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 96, 96)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 3, 102, 102)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 48, 48)   9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 64, 48, 48)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 48, 48)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 64, 50, 50)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 24, 24)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 64, 24, 24)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 24, 24)   0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 64, 26, 26)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 192, 24, 24)  110784      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 192, 24, 24)  768         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 192, 24, 24)  0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 192, 26, 26)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 192, 12, 12)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv1 (Conv2D) (None, 96, 12, 12)   18528       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv1 (Conv2D) (None, 16, 12, 12)   3088        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn1 (BatchNorm (None, 96, 12, 12)   384         inception_3a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn1 (BatchNorm (None, 16, 12, 12)   64          inception_3a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 96, 12, 12)   0           inception_3a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 12, 12)   0           inception_3a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 192, 5, 5)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 96, 14, 14)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_conv (Conv2D) (None, 32, 5, 5)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv2 (Conv2D) (None, 128, 12, 12)  110720      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv2 (Conv2D) (None, 32, 12, 12)   12832       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_bn (BatchNorm (None, 32, 5, 5)     128         inception_3a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_conv (Conv2D)  (None, 64, 12, 12)   12352       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn2 (BatchNorm (None, 128, 12, 12)  512         inception_3a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn2 (BatchNorm (None, 32, 12, 12)   128         inception_3a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 5, 5)     0           inception_3a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_bn (BatchNorma (None, 64, 12, 12)   256         inception_3a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 12, 12)  0           inception_3a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 12, 12)   0           inception_3a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 32, 12, 12)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 12, 12)   0           inception_3a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 12, 12)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 zero_padding2d_7[0][0]           \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv1 (Conv2D) (None, 96, 12, 12)   24672       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv1 (Conv2D) (None, 32, 12, 12)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn1 (BatchNorm (None, 96, 12, 12)   384         inception_3b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn1 (BatchNorm (None, 32, 12, 12)   128         inception_3b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 96, 12, 12)   0           inception_3b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 12, 12)   0           inception_3b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 256, 4, 4)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 96, 14, 14)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 32, 16, 16)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_conv (Conv2D) (None, 64, 4, 4)     16448       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv2 (Conv2D) (None, 128, 12, 12)  110720      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv2 (Conv2D) (None, 64, 12, 12)   51264       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_bn (BatchNorm (None, 64, 4, 4)     256         inception_3b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_conv (Conv2D)  (None, 64, 12, 12)   16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn2 (BatchNorm (None, 128, 12, 12)  512         inception_3b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn2 (BatchNorm (None, 64, 12, 12)   256         inception_3b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 4, 4)     0           inception_3b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_bn (BatchNorma (None, 64, 12, 12)   256         inception_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 12, 12)  0           inception_3b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 12, 12)   0           inception_3b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 64, 12, 12)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 12, 12)   0           inception_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 320, 12, 12)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 zero_padding2d_10[0][0]          \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv1 (Conv2D) (None, 128, 12, 12)  41088       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv1 (Conv2D) (None, 32, 12, 12)   10272       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn1 (BatchNorm (None, 128, 12, 12)  512         inception_3c_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn1 (BatchNorm (None, 32, 12, 12)   128         inception_3c_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 12, 12)  0           inception_3c_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 12, 12)   0           inception_3c_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 128, 14, 14)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 32, 16, 16)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv2 (Conv2D) (None, 256, 6, 6)    295168      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv2 (Conv2D) (None, 64, 6, 6)     51264       zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn2 (BatchNorm (None, 256, 6, 6)    1024        inception_3c_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn2 (BatchNorm (None, 64, 6, 6)     256         inception_3c_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 320, 5, 5)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 6, 6)    0           inception_3c_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 6, 6)     0           inception_3c_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 320, 6, 6)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 640, 6, 6)    0           activation_17[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv1 (Conv2D) (None, 96, 6, 6)     61536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv1 (Conv2D) (None, 32, 6, 6)     20512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn1 (BatchNorm (None, 96, 6, 6)     384         inception_4a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn1 (BatchNorm (None, 32, 6, 6)     128         inception_4a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 96, 6, 6)     0           inception_4a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 6, 6)     0           inception_4a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 640, 2, 2)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 96, 8, 8)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 32, 10, 10)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_conv (Conv2D) (None, 128, 2, 2)    82048       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv2 (Conv2D) (None, 192, 6, 6)    166080      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv2 (Conv2D) (None, 64, 6, 6)     51264       zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_bn (BatchNorm (None, 128, 2, 2)    512         inception_4a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_conv (Conv2D)  (None, 256, 6, 6)    164096      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn2 (BatchNorm (None, 192, 6, 6)    768         inception_4a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn2 (BatchNorm (None, 64, 6, 6)     256         inception_4a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128, 2, 2)    0           inception_4a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_bn (BatchNorma (None, 256, 6, 6)    1024        inception_4a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 192, 6, 6)    0           inception_4a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 6, 6)     0           inception_4a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 128, 6, 6)    0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 256, 6, 6)    0           inception_4a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 640, 6, 6)    0           activation_21[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 zero_padding2d_16[0][0]          \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_conv1 (Conv2D) (None, 160, 6, 6)    102560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_conv1 (Conv2D) (None, 64, 6, 6)     41024       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_bn1 (BatchNorm (None, 160, 6, 6)    640         inception_4e_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_bn1 (BatchNorm (None, 64, 6, 6)     256         inception_4e_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 160, 6, 6)    0           inception_4e_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 6, 6)     0           inception_4e_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 160, 8, 8)    0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 64, 10, 10)   0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_conv2 (Conv2D) (None, 256, 3, 3)    368896      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_conv2 (Conv2D) (None, 128, 3, 3)    204928      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_bn2 (BatchNorm (None, 256, 3, 3)    1024        inception_4e_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_bn2 (BatchNorm (None, 128, 3, 3)    512         inception_4e_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 640, 2, 2)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 256, 3, 3)    0           inception_4e_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128, 3, 3)    0           inception_4e_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 640, 3, 3)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024, 3, 3)   0           activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv1 (Conv2D) (None, 96, 3, 3)     98400       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn1 (BatchNorm (None, 96, 3, 3)     384         inception_5a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 96, 3, 3)     0           inception_5a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1024, 1, 1)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 96, 5, 5)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_conv (Conv2D) (None, 96, 1, 1)     98400       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv2 (Conv2D) (None, 384, 3, 3)    332160      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_bn (BatchNorm (None, 96, 1, 1)     384         inception_5a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_conv (Conv2D)  (None, 256, 3, 3)    262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn2 (BatchNorm (None, 384, 3, 3)    1536        inception_5a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 96, 1, 1)     0           inception_5a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_bn (BatchNorma (None, 256, 3, 3)    1024        inception_5a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 384, 3, 3)    0           inception_5a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 96, 3, 3)     0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256, 3, 3)    0           inception_5a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 736, 3, 3)    0           activation_31[0][0]              \n",
      "                                                                 zero_padding2d_21[0][0]          \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv1 (Conv2D) (None, 96, 3, 3)     70752       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn1 (BatchNorm (None, 96, 3, 3)     384         inception_5b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 96, 3, 3)     0           inception_5b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 736, 1, 1)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 96, 5, 5)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_conv (Conv2D) (None, 96, 1, 1)     70752       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv2 (Conv2D) (None, 384, 3, 3)    332160      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_bn (BatchNorm (None, 96, 1, 1)     384         inception_5b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_conv (Conv2D)  (None, 256, 3, 3)    188672      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn2 (BatchNorm (None, 384, 3, 3)    1536        inception_5b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 96, 1, 1)     0           inception_5b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_bn (BatchNorma (None, 256, 3, 3)    1024        inception_5b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 384, 3, 3)    0           inception_5b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 96, 3, 3)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 256, 3, 3)    0           inception_5b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 736, 3, 3)    0           activation_35[0][0]              \n",
      "                                                                 zero_padding2d_23[0][0]          \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 736, 1, 1)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 736)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 128)          94336       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128)          0           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FRmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_database():\n",
    "    database = {}\n",
    "\n",
    "    # load all the images of individuals to recognize into the database\n",
    "    for file in glob.glob(\"images/*\"):\n",
    "        identity = os.path.splitext(os.path.basename(file))[0].strip('NISDCC-_6g')\n",
    "        print (identity)\n",
    "        database[identity] = img_path_to_encoding(file, FRmodel)\n",
    "\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_embeddings = prepare_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15641016,  0.05222272, -0.05158556, -0.06820939, -0.06904899,\n",
       "         0.04225592, -0.26231194, -0.00162374, -0.08420499, -0.01482287,\n",
       "        -0.0102939 ,  0.15204217, -0.09350223,  0.04751017,  0.0400623 ,\n",
       "        -0.00481695,  0.0344524 , -0.08433454, -0.14721756, -0.03183836,\n",
       "         0.07841872, -0.00340025, -0.07460167, -0.09021194,  0.01456932,\n",
       "        -0.06377899,  0.09303121, -0.04148884, -0.16686536,  0.09871604,\n",
       "        -0.0544215 , -0.05322067,  0.09734283,  0.02512276,  0.12048358,\n",
       "        -0.01232122,  0.14697868, -0.06088248,  0.08042841,  0.09282817,\n",
       "        -0.06127114,  0.00623025, -0.06747863,  0.1769361 , -0.11723821,\n",
       "        -0.00656794,  0.04283603,  0.1061457 , -0.227117  , -0.10668667,\n",
       "        -0.12959589, -0.02904997,  0.06846651, -0.00067627, -0.0098416 ,\n",
       "        -0.18507616, -0.16815072,  0.00256527, -0.03629062,  0.00303761,\n",
       "         0.00713849,  0.07191086,  0.14574409, -0.01347527,  0.03694312,\n",
       "         0.00673224,  0.12085769, -0.00368221,  0.06837099,  0.18328674,\n",
       "         0.05205655,  0.0150786 , -0.06060399, -0.10487723,  0.04836895,\n",
       "        -0.0293176 , -0.07412621,  0.05075434, -0.07510103, -0.08552957,\n",
       "         0.09787653,  0.09990478,  0.01175603, -0.02447292, -0.1387033 ,\n",
       "         0.09897517,  0.0407648 ,  0.09004751, -0.0340315 , -0.06252151,\n",
       "         0.09756246, -0.10346504, -0.09763867, -0.09750416, -0.04809855,\n",
       "        -0.10427346,  0.04795389, -0.05620671, -0.09640336,  0.09526552,\n",
       "        -0.05229853,  0.03425271,  0.06262504,  0.05456972,  0.11745493,\n",
       "        -0.09148137, -0.18438755,  0.04990599,  0.00633929, -0.0720171 ,\n",
       "        -0.09070797, -0.01712986, -0.06451931,  0.19877377,  0.14844456,\n",
       "         0.0098753 , -0.0644844 ,  0.00863391,  0.01665523,  0.02443655,\n",
       "        -0.14269319,  0.02410518,  0.03465923, -0.07861972,  0.0196125 ,\n",
       "         0.07103436, -0.07217567, -0.02834973]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_embeddings['001_001_001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_str=[]\n",
    "\n",
    "t1= time.time()\n",
    "for i in range(1,13):\n",
    "    for ja in range(1,6):\n",
    "        for k in range(22,52):\n",
    "             for jn in range(1,6):\n",
    "                    for jp in range(1,6):\n",
    "                        print (i,ja,k,jn,jp)\n",
    "                        if (jp!=ja):\n",
    "                            \n",
    "                            if(i<10):\n",
    "                                a='00'+ str(i)+'_00'+str(i)+'_00'+str(ja)\n",
    "                                b='00'+ str(i) +'_00'+str(i)+'_00'+str(jp)\n",
    "                                c='0'+str(k)+'_00'+str(i)+'_00'+str(jn)\n",
    "                            else:\n",
    "                                a='0'+str(i)+'_0'+str(i)+'_00'+str(ja)\n",
    "                                b='0'+str(i)+'_0'+str(i)+'_00'+str(jp)\n",
    "                                c='0'+str(k)+'_0'+str(i)+'_00'+str(jn)\n",
    "                            \n",
    "                            x= (a,b,c)\n",
    "                            triplet_str.append(x)\n",
    "                        \n",
    "                    \n",
    "t2=time.time()\n",
    "\n",
    "print (t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(triplet_encoding, alpha = 0.3):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = triplet_encoding[0], triplet_encoding[1], triplet_encoding[2]\n",
    "    \n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''final_triplet_loss=[]\n",
    "for i in triplet_str:\n",
    "    print (i)\n",
    "    x=(train_images_embeddings[i[0]],train_images_embeddings[i[1]],train_images_embeddings[i[2]])\n",
    "    loss=triplet_loss(x, alpha = 0.3)\n",
    "    final_triplet_loss.append(loss)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
